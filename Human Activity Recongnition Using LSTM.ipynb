{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Human Activity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These days Smartphones have become an integral part of our life. We cannot assume our life without a mobile phone. Since, the advent of Smartphones, a revolution has been created in the mobile communication industry. Smartphones are not just restricted for calling these days. Infact, they are more often used for entertainment purpose.\n",
    "\n",
    "Smartphone manufacturing companies load Smartphones with various sensors to enhance the user experinece. Two of the such sensors are Accelerometer and Gyroscope. Accelerometer measures acceleration while Gyroscope measures angular velocity.\n",
    "\n",
    "Here, we will try to use the data provided by accelerometer and gyroscope of Smartphone to classify the activity which a Smartphone user is performing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why this is Useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These days, in addition to Smartphones, we are also using Smart-Watches like Fitbit or Apple-Watch, which help us to track our health. They monitor our each activity throughout the day check how many calories we have burnt. How many hours have we slept. However, in addition to Accelerometer and Gyroscope, they also use Heart-Rate data to monitor our activity. Since, we only have Smartphone data so just by using Accelerometer and Gyroscope data we will monitor the activity of a person. This software can then be converted into an App which can be downloaded in Smartphone. Hence, a person who has Smartphone can monitor his/her health using this App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information about Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Data is recorded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING-UPSTAIRS, WALKING-DOWNSTAIRS, SITTING-DOWN, STANDING-UP, LAYING-DOWN) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. 5.2. Features\n",
    "\n",
    "These sensor signals are pre-processed by applying noise filters and then sampled in fixed-width windows(sliding windows) of 2.56 seconds each with 50% overlap. i.e., each window has 128 readings. A 128 size vector is created from each window.\n",
    "From Each window or to be more precise, from each 128 readings domain experts from signal processing have engineered feature vector of size 561 by calculating variables from the time and frequency domain. In our dataset, each data-point represents a window with different readings.\n",
    "561 features are stored in the file \"Features.docx\". Check it out.\n",
    "Check out 561 features here.(In your blog give here the link of the docx file of features which you upload on github).\n",
    "The acceleration signal was separated into Body and Gravity acceleration signals(tBodyAcc-XYZ and tGravityAcc-XYZ) using some low pass filter with corner frequency of 0.3Hz.\n",
    "After that, the body linear acceleration and angular velocity were derived in time to obtain jerk signals (tBodyAccJerk-XYZ and tBodyGyroJerk-XYZ).\n",
    "The magnitude of these 3-dimensional signals were calculated using the Euclidian norm. This magnitudes are represented as features with names like tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag and tBodyGyroJerkMag.\n",
    "Finally, We've got frequency domain signals from some of the available signals by applying a FFT (Fast Fourier Transform). These signals obtained were labelled with prefix 'f' just like original signals with prefix 't'. These signals are labelled as fBodyAcc-XYZ, fBodyGyroMag etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the signals that we got so far.\n",
    "\n",
    "tBodyAcc-XYZ\n",
    "tGravityAcc-XYZ\n",
    "tBodyAccJerk-XYZ\n",
    "tBodyGyro-XYZ\n",
    "tBodyGyroJerk-XYZ\n",
    "tBodyAccMag\n",
    "tGravityAccMag\n",
    "tBodyAccJerkMag\n",
    "tBodyGyroMag\n",
    "tBodyGyroJerkMag\n",
    "fBodyAcc-XYZ\n",
    "fBodyAccJerk-XYZ\n",
    "fBodyGyro-XYZ\n",
    "fBodyAccMag\n",
    "fBodyAccJerkMag\n",
    "fBodyGyroMag\n",
    "fBodyGyroJerkMag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9 We can estimate some set of variables from the above signals. i.e., We will estimate the following properties on each and every signal that we recorded so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean(): Mean value\n",
    "std(): Standard deviation\n",
    "mad(): Median absolute deviation\n",
    "max(): Largest value in array\n",
    "min(): Smallest value in array\n",
    "sma(): Signal magnitude area\n",
    "energy(): Energy measure. Sum of the squares divided by the number of values.\n",
    "iqr(): Inter-quartile range\n",
    "entropy(): Signal entropy\n",
    "arCoeff(): Auto-regression coefficients with Burg order equal to 4\n",
    "correlation(): correlation coefficient between two signals\n",
    "maxInds(): index of the frequency component with largest magnitude\n",
    "meanFreq(): Weighted average of the frequency components to obtain a mean frequency\n",
    "skewness(): skewness of the frequency domain signal\n",
    "kurtosis(): kurtosis of the frequency domain signal\n",
    "bandsEnergy(): Energy of a frequency interval within the 64 bins of the FFT of each window.\n",
    "angle(): Angle between to vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 We can obtain some other vectors by taking the average of signals in a single window sample. These are used on the angle() variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gravityMean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-d3f38673bd33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgravityMean\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtBodyAccMean\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtBodyAccJerkMean\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtBodyGyroMean\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtBodyGyroJerkMean\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gravityMean' is not defined"
     ]
    }
   ],
   "source": [
    "gravityMean\n",
    "tBodyAccMean\n",
    "tBodyAccJerkMean\n",
    "tBodyGyroMean\n",
    "tBodyGyroJerkMean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is downloaded from following source:\n",
    "https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Overview of Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accelerometer and Gyroscope readings are taken from 30 volunteers(referred as subjects) while performing the following 6 Activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These activites are encoded as follows:\n",
    "WALKING-- 1\n",
    "WALKING_UPSTAIRS-- 2\n",
    "WALKING_DOWNSTAIRS-- 3\n",
    "SITTING-- 4\n",
    "STANDING-- 5\n",
    "LYING-- 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Readings are divided into a window of 2.56 seconds with 50% overlapping.\n",
    "2.Accelerometer readings are divided into gravity acceleration and body acceleration readings, which has x, y and z components each.\n",
    "3.Gyroscope readings are the measure of angular velocities which has x, y and z components.\n",
    "4.Jerk signals are calculated for Body-Acceleration readings.\n",
    "5.Fourier Transforms are made on the above time readings to obtain frequency readings.\n",
    "6.Now, on all the base signal readings., mean, max, mad, sma, arcoefficient, energy-bands, entropy etc., are calculated for each window.\n",
    "7.Extra features are calculated by taking the average of signals in a single window sample. These are used on the angle() variable.\n",
    "8.Finally, we got feature vector of 561 features and these features are given in the dataset.\n",
    "Each window of readings is a data-point of 561 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y-Encoded Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WALKING-- 1\n",
    "WALKING_UPSTAIRS-- 2\n",
    "WALKING_DOWNSTAIRS-- 3\n",
    "SITTING-- 4\n",
    "STANDING-- 5\n",
    "LYING-- 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work-flow is as follows:\n",
    "\n",
    "1.Domain experts from the field of Signal Processing collects the data from Accelerometer and Gyroscope of Smartphone.\n",
    "2.They break up the data in the time window of 2.56 seconds with 50% overlapping i.e., 128 reading\n",
    "3.They engineered 561 features from each time window of 2.56 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using either human engineered 561 feature data or raw features of 128 reading, our goal is to predict one of the six activities that a Smartphone user is performing at that 2.56 Seconds time window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using either human engineered 561 feature data or raw features of 128 reading, our goal is to predict one of the six activities that a Smartphone user is performing at that 2.56 Seconds time window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective and Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.No Low latency requirement.\n",
    "2.Errors are not much costly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the Accelerometer and Gyroscope are tri-axial, means that they measure acceleration and angular-velocity respectively in all the three axis namely X-axis, Y-axis and Z-axis. So, we have in total six time-series data. Given this six time-series data, we want to predict six activities namely Walking or Walking-Upstairs or Walking-Downstairs or Lying-Down or Standing-Up or Sitting-Down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the outset, this is a multi-class classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Problem Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the Accelerometer and Gyroscope are tri-axial, means that they measure acceleration and angular-velocity respectively in all the three axis namely X-axis, Y-axis and Z-axis. So, we have in total six time-series data. Given this six time-series data, we want to predict six activities namely Walking or Walking-Upstairs or Walking-Downstairs or Lying-Down or Standing-Up or Sitting-Down.\n",
    "\n",
    "At the outset, this is a multi-class classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.We will use Accuracy as one of the metric.\n",
    "2.We will also use Confusion-Matrix to check that in which two activities our model is confused and predicting incorrect activity. For example, between Standing-Up and Sitting-Down. Between Walking-Upstairs and Walking-Downstairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the data is present in 'UCI_HAR_dataset/' folder in present working directory.\n",
    "Feature names are present in 'UCI_HAR_dataset/features.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Data\n",
    "'UCI_HAR_dataset/train/X_train.txt'\n",
    "'UCI_HAR_dataset/train/subject_train.txt'\n",
    "'UCI_HAR_dataset/train/y_train.txt'\n",
    "Test Data\n",
    "'UCI_HAR_dataset/test/X_test.txt'\n",
    "'UCI_HAR_dataset/test/subject_test.txt'\n",
    "'UCI_HAR_dataset/test/y_test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-Points Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.30 test-subjects data is randomly split to 70%(21) train and 30%(7) test data.\n",
    "2.Each data-point corresponds one of the 6 Activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan of Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply classical Machine Learning models on these 561 sized domain expert engineered features.\n",
    "As we know that LSTM works well on time-series data, so we have decided that we will apply LSTM of Recurrent Neural Networks on 128 sized raw readings that we obtained from accelerometer and gyroscope signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR = 'UCI_HAR_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "\n",
    "    return pd.get_dummies(y).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saurabh\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Importing tensorflow\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring a session\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Keras\n",
    "from keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "epochs = 300\n",
    "batch_size = 32\n",
    "n_hidden = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saurabh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Loading the train and test data\n",
    "X_train, X_test, Y_train, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "9\n",
      "7352\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Defining the Architecture of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 64)                18944     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 19,334\n",
      "Trainable params: 19,334\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/300\n",
      "7352/7352 [==============================] - 24s 3ms/step - loss: 1.4284 - acc: 0.3644 - val_loss: 1.3755 - val_acc: 0.3431\n",
      "Epoch 2/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 1.3148 - acc: 0.3923 - val_loss: 1.3391 - val_acc: 0.4262\n",
      "Epoch 3/300\n",
      "7352/7352 [==============================] - 24s 3ms/step - loss: 1.2377 - acc: 0.4463 - val_loss: 1.2617 - val_acc: 0.4740s - loss: 1.269\n",
      "Epoch 4/300\n",
      "7352/7352 [==============================] - 23s 3ms/step - loss: 1.1586 - acc: 0.4737 - val_loss: 1.3795 - val_acc: 0.4092\n",
      "Epoch 5/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 1.2517 - acc: 0.4286 - val_loss: 1.2629 - val_acc: 0.3997\n",
      "Epoch 6/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 1.1608 - acc: 0.5076 - val_loss: 1.0618 - val_acc: 0.5643\n",
      "Epoch 7/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.9851 - acc: 0.5613 - val_loss: 0.9977 - val_acc: 0.5046\n",
      "Epoch 8/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.9568 - acc: 0.5768 - val_loss: 0.9901 - val_acc: 0.5704\n",
      "Epoch 9/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.8428 - acc: 0.6217 - val_loss: 0.9000 - val_acc: 0.5792\n",
      "Epoch 10/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.7760 - acc: 0.6328 - val_loss: 0.8497 - val_acc: 0.6060s: 0.7 - ETA: 2s - loss:  - ETA: 0s - loss: 0.7759 - acc: 0.6\n",
      "Epoch 11/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.7391 - acc: 0.6506 - val_loss: 0.7869 - val_acc: 0.6417\n",
      "Epoch 12/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.7065 - acc: 0.6737 - val_loss: 0.7655 - val_acc: 0.6637\n",
      "Epoch 13/300\n",
      "7352/7352 [==============================] - 23s 3ms/step - loss: 0.5739 - acc: 0.7421 - val_loss: 0.7396 - val_acc: 0.7004\n",
      "Epoch 14/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.5620 - acc: 0.7606 - val_loss: 0.8626 - val_acc: 0.6546 1s - loss: 0.5502\n",
      "Epoch 15/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.4878 - acc: 0.7818 - val_loss: 0.6276 - val_acc: 0.7431\n",
      "Epoch 16/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.6082 - acc: 0.7448 - val_loss: 0.7651 - val_acc: 0.5792\n",
      "Epoch 17/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.8085 - acc: 0.6663 - val_loss: 0.8235 - val_acc: 0.7418\n",
      "Epoch 18/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.5122 - acc: 0.7990 - val_loss: 0.5995 - val_acc: 0.7777\n",
      "Epoch 19/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.6121 - acc: 0.7682 - val_loss: 0.7280 - val_acc: 0.7021\n",
      "Epoch 20/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.5246 - acc: 0.8075 - val_loss: 0.4797 - val_acc: 0.8066\n",
      "Epoch 21/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.3587 - acc: 0.8811 - val_loss: 0.6818 - val_acc: 0.8018\n",
      "Epoch 22/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.4166 - acc: 0.8690 - val_loss: 0.4884 - val_acc: 0.8371\n",
      "Epoch 23/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.3675 - acc: 0.8950 - val_loss: 1.6821 - val_acc: 0.5602\n",
      "Epoch 24/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.5638 - acc: 0.7954 - val_loss: 0.5362 - val_acc: 0.8069\n",
      "Epoch 25/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.3414 - acc: 0.8794 - val_loss: 0.4615 - val_acc: 0.8402\n",
      "Epoch 26/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.2948 - acc: 0.9036 - val_loss: 0.4160 - val_acc: 0.8561\n",
      "Epoch 27/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.2557 - acc: 0.9112 - val_loss: 0.4476 - val_acc: 0.8466\n",
      "Epoch 28/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.2705 - acc: 0.9108 - val_loss: 0.4708 - val_acc: 0.8534\n",
      "Epoch 29/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.2208 - acc: 0.9187 - val_loss: 0.3703 - val_acc: 0.8734\n",
      "Epoch 30/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.2366 - acc: 0.9188 - val_loss: 0.2981 - val_acc: 0.8870\n",
      "Epoch 31/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1712 - acc: 0.9377 - val_loss: 0.3246 - val_acc: 0.8921\n",
      "Epoch 32/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1859 - acc: 0.9323 - val_loss: 0.2655 - val_acc: 0.9002\n",
      "Epoch 33/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1516 - acc: 0.9415 - val_loss: 0.2949 - val_acc: 0.8965\n",
      "Epoch 34/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.4006 - acc: 0.8566 - val_loss: 0.5065 - val_acc: 0.8066\n",
      "Epoch 35/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.2925 - acc: 0.8991 - val_loss: 0.3625 - val_acc: 0.8446\n",
      "Epoch 36/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1952 - acc: 0.9338 - val_loss: 0.2802 - val_acc: 0.8870\n",
      "Epoch 37/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1562 - acc: 0.9423 - val_loss: 0.2990 - val_acc: 0.8789\n",
      "Epoch 38/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.2587 - acc: 0.9127 - val_loss: 0.2999 - val_acc: 0.8839\n",
      "Epoch 39/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1869 - acc: 0.9368 - val_loss: 0.2760 - val_acc: 0.8924\n",
      "Epoch 40/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1435 - acc: 0.9457 - val_loss: 0.3344 - val_acc: 0.8873\n",
      "Epoch 41/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1460 - acc: 0.9445 - val_loss: 0.3837 - val_acc: 0.8955\n",
      "Epoch 42/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1453 - acc: 0.9460 - val_loss: 0.2489 - val_acc: 0.9033\n",
      "Epoch 43/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1309 - acc: 0.9476 - val_loss: 0.2544 - val_acc: 0.9043\n",
      "Epoch 44/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1829 - acc: 0.9339 - val_loss: 0.2502 - val_acc: 0.9009\n",
      "Epoch 45/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1778 - acc: 0.9381 - val_loss: 0.2616 - val_acc: 0.8985\n",
      "Epoch 46/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.2386 - acc: 0.9240 - val_loss: 0.2433 - val_acc: 0.9179\n",
      "Epoch 47/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.2023 - acc: 0.9279 - val_loss: 0.2375 - val_acc: 0.9206\n",
      "Epoch 48/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1627 - acc: 0.9467 - val_loss: 0.3445 - val_acc: 0.8901\n",
      "Epoch 49/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1717 - acc: 0.9430 - val_loss: 0.2563 - val_acc: 0.9145\n",
      "Epoch 50/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1299 - acc: 0.9520 - val_loss: 0.2715 - val_acc: 0.9152\n",
      "Epoch 51/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1379 - acc: 0.9468 - val_loss: 0.3342 - val_acc: 0.9046\n",
      "Epoch 52/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1245 - acc: 0.9482 - val_loss: 0.2143 - val_acc: 0.9260\n",
      "Epoch 53/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1499 - acc: 0.9429 - val_loss: 0.2540 - val_acc: 0.9209\n",
      "Epoch 54/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1514 - acc: 0.9408 - val_loss: 0.2265 - val_acc: 0.9172\n",
      "Epoch 55/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.2301 - acc: 0.9230 - val_loss: 0.3076 - val_acc: 0.8972\n",
      "Epoch 56/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1780 - acc: 0.9314 - val_loss: 0.3027 - val_acc: 0.9023\n",
      "Epoch 57/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1400 - acc: 0.9484 - val_loss: 0.2572 - val_acc: 0.9121\n",
      "Epoch 58/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.2840 - acc: 0.9112 - val_loss: 0.3329 - val_acc: 0.8792\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1785 - acc: 0.9389 - val_loss: 0.3258 - val_acc: 0.8935\n",
      "Epoch 60/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1423 - acc: 0.9491 - val_loss: 0.3077 - val_acc: 0.9006\n",
      "Epoch 61/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1715 - acc: 0.9368 - val_loss: 0.3258 - val_acc: 0.9077\n",
      "Epoch 62/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1732 - acc: 0.9410 - val_loss: 0.2511 - val_acc: 0.9104\n",
      "Epoch 63/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1449 - acc: 0.9468 - val_loss: 0.2585 - val_acc: 0.9125\n",
      "Epoch 64/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1437 - acc: 0.9476 - val_loss: 0.2573 - val_acc: 0.9135\n",
      "Epoch 65/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1262 - acc: 0.9518 - val_loss: 0.2454 - val_acc: 0.9169\n",
      "Epoch 66/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1207 - acc: 0.9532 - val_loss: 0.3169 - val_acc: 0.8951\n",
      "Epoch 67/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1532 - acc: 0.9440 - val_loss: 0.3391 - val_acc: 0.9087\n",
      "Epoch 68/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1256 - acc: 0.9493 - val_loss: 0.1996 - val_acc: 0.9226\n",
      "Epoch 69/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1167 - acc: 0.9540 - val_loss: 0.2170 - val_acc: 0.9264\n",
      "Epoch 70/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1373 - acc: 0.9471 - val_loss: 0.2798 - val_acc: 0.9165\n",
      "Epoch 71/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1417 - acc: 0.9406 - val_loss: 0.2237 - val_acc: 0.9189\n",
      "Epoch 72/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1263 - acc: 0.9441 - val_loss: 0.1891 - val_acc: 0.9233\n",
      "Epoch 73/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1319 - acc: 0.9472 - val_loss: 0.1869 - val_acc: 0.9281\n",
      "Epoch 74/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1806 - acc: 0.9400 - val_loss: 0.2450 - val_acc: 0.9165\n",
      "Epoch 75/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1956 - acc: 0.9385 - val_loss: 0.2274 - val_acc: 0.9213\n",
      "Epoch 76/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1451 - acc: 0.9455 - val_loss: 0.2262 - val_acc: 0.9233\n",
      "Epoch 77/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1225 - acc: 0.9480 - val_loss: 0.2293 - val_acc: 0.9213\n",
      "Epoch 78/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1197 - acc: 0.9501 - val_loss: 0.3045 - val_acc: 0.9138\n",
      "Epoch 79/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1202 - acc: 0.9514 - val_loss: 0.2074 - val_acc: 0.9250\n",
      "Epoch 80/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1661 - acc: 0.9387 - val_loss: 0.2255 - val_acc: 0.9253\n",
      "Epoch 81/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1982 - acc: 0.9357 - val_loss: 0.4807 - val_acc: 0.9036\n",
      "Epoch 82/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1338 - acc: 0.9509 - val_loss: 0.2289 - val_acc: 0.9230\n",
      "Epoch 83/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1176 - acc: 0.9551 - val_loss: 0.2249 - val_acc: 0.9284\n",
      "Epoch 84/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.2776 - acc: 0.9161 - val_loss: 0.3171 - val_acc: 0.9057 ETA: 2s \n",
      "Epoch 85/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1763 - acc: 0.9359 - val_loss: 0.2374 - val_acc: 0.9108\n",
      "Epoch 86/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1629 - acc: 0.9347 - val_loss: 0.2102 - val_acc: 0.9169\n",
      "Epoch 87/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1494 - acc: 0.9400 - val_loss: 0.2208 - val_acc: 0.9250A: 2s\n",
      "Epoch 88/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1376 - acc: 0.9463 - val_loss: 0.2118 - val_acc: 0.9247\n",
      "Epoch 89/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1353 - acc: 0.9456 - val_loss: 0.2173 - val_acc: 0.9267\n",
      "Epoch 90/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1405 - acc: 0.9465 - val_loss: 0.2184 - val_acc: 0.9247\n",
      "Epoch 91/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1277 - acc: 0.9490 - val_loss: 0.2253 - val_acc: 0.9291\n",
      "Epoch 92/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1315 - acc: 0.9467 - val_loss: 0.2293 - val_acc: 0.9274\n",
      "Epoch 93/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1290 - acc: 0.9470 - val_loss: 0.2380 - val_acc: 0.9247\n",
      "Epoch 94/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1273 - acc: 0.9502 - val_loss: 0.2712 - val_acc: 0.9237\n",
      "Epoch 95/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1315 - acc: 0.9468 - val_loss: 0.1919 - val_acc: 0.9294\n",
      "Epoch 96/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.2131 - acc: 0.9305 - val_loss: 0.2716 - val_acc: 0.9063\n",
      "Epoch 97/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1738 - acc: 0.9395 - val_loss: 0.2716 - val_acc: 0.9118\n",
      "Epoch 98/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1344 - acc: 0.9512 - val_loss: 0.2322 - val_acc: 0.9240\n",
      "Epoch 99/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1254 - acc: 0.9525 - val_loss: 0.2488 - val_acc: 0.9186\n",
      "Epoch 100/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1246 - acc: 0.9517 - val_loss: 0.2404 - val_acc: 0.9192\n",
      "Epoch 101/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1217 - acc: 0.9528 - val_loss: 0.2236 - val_acc: 0.9175\n",
      "Epoch 102/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1160 - acc: 0.9535 - val_loss: 0.2631 - val_acc: 0.9036\n",
      "Epoch 103/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1241 - acc: 0.9493 - val_loss: 0.3104 - val_acc: 0.9111\n",
      "Epoch 104/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1266 - acc: 0.9464 - val_loss: 0.2004 - val_acc: 0.9226\n",
      "Epoch 105/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1156 - acc: 0.9548 - val_loss: 0.2058 - val_acc: 0.9298\n",
      "Epoch 106/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1168 - acc: 0.9533 - val_loss: 0.2105 - val_acc: 0.9270\n",
      "Epoch 107/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1134 - acc: 0.9563 - val_loss: 0.2126 - val_acc: 0.9277\n",
      "Epoch 108/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1260 - acc: 0.9538 - val_loss: 0.2244 - val_acc: 0.9257 0.1267 - acc: 0.953 - ETA: 1s - loss: 0.1267\n",
      "Epoch 109/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1281 - acc: 0.9513 - val_loss: 0.2337 - val_acc: 0.9253\n",
      "Epoch 110/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1240 - acc: 0.9523 - val_loss: 0.2744 - val_acc: 0.9175\n",
      "Epoch 111/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1355 - acc: 0.9508 - val_loss: 0.2014 - val_acc: 0.9376\n",
      "Epoch 112/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1168 - acc: 0.9544 - val_loss: 0.2315 - val_acc: 0.9274A: 2s - l\n",
      "Epoch 113/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1221 - acc: 0.9528 - val_loss: 0.2320 - val_acc: 0.9308\n",
      "Epoch 114/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1194 - acc: 0.9551 - val_loss: 0.2127 - val_acc: 0.9233\n",
      "Epoch 115/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1147 - acc: 0.9570 - val_loss: 0.1955 - val_acc: 0.9240\n",
      "Epoch 116/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1139 - acc: 0.9554 - val_loss: 0.2120 - val_acc: 0.9216\n",
      "Epoch 117/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1105 - acc: 0.9548 - val_loss: 0.2068 - val_acc: 0.9277\n",
      "Epoch 118/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1476 - acc: 0.9427 - val_loss: 0.3411 - val_acc: 0.9097\n",
      "Epoch 119/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1338 - acc: 0.9421 - val_loss: 0.2694 - val_acc: 0.9158\n",
      "Epoch 120/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1197 - acc: 0.9505 - val_loss: 0.2509 - val_acc: 0.9277\n",
      "Epoch 121/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1667 - acc: 0.9380 - val_loss: 0.3682 - val_acc: 0.9128\n",
      "Epoch 122/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1307 - acc: 0.9463 - val_loss: 0.2353 - val_acc: 0.9260\n",
      "Epoch 123/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1149 - acc: 0.9516 - val_loss: 0.2196 - val_acc: 0.9250\n",
      "Epoch 124/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1127 - acc: 0.9512 - val_loss: 0.2116 - val_acc: 0.9308\n",
      "Epoch 125/300\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1130 - acc: 0.9529 - val_loss: 0.2314 - val_acc: 0.9169\n",
      "Epoch 126/300\n",
      "7352/7352 [==============================] - 1253s 170ms/step - loss: 0.1120 - acc: 0.9557 - val_loss: 0.2418 - val_acc: 0.9253\n",
      "Epoch 127/300\n",
      "7352/7352 [==============================] - 43s 6ms/step - loss: 0.1275 - acc: 0.9495 - val_loss: 0.2929 - val_acc: 0.9203\n",
      "Epoch 128/300\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.1185 - acc: 0.9506 - val_loss: 0.2296 - val_acc: 0.9291\n",
      "Epoch 129/300\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.1074 - acc: 0.9547 - val_loss: 0.2433 - val_acc: 0.9233\n",
      "Epoch 130/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1272 - acc: 0.9484 - val_loss: 0.2292 - val_acc: 0.9287\n",
      "Epoch 131/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1192 - acc: 0.9499 - val_loss: 0.2674 - val_acc: 0.9182\n",
      "Epoch 132/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1190 - acc: 0.9538 - val_loss: 0.2881 - val_acc: 0.9179\n",
      "Epoch 133/300\n",
      "7352/7352 [==============================] - 38s 5ms/step - loss: 0.1170 - acc: 0.9504 - val_loss: 0.2898 - val_acc: 0.9264\n",
      "Epoch 134/300\n",
      "7352/7352 [==============================] - 42s 6ms/step - loss: 0.1171 - acc: 0.9529 - val_loss: 0.2810 - val_acc: 0.9223\n",
      "Epoch 135/300\n",
      "7352/7352 [==============================] - 43s 6ms/step - loss: 0.1133 - acc: 0.9533 - val_loss: 0.2598 - val_acc: 0.9284\n",
      "Epoch 136/300\n",
      "7352/7352 [==============================] - 42s 6ms/step - loss: 0.1079 - acc: 0.9524 - val_loss: 0.2508 - val_acc: 0.9267\n",
      "Epoch 137/300\n",
      "7352/7352 [==============================] - 43s 6ms/step - loss: 0.1284 - acc: 0.9490 - val_loss: 0.2532 - val_acc: 0.9260\n",
      "Epoch 138/300\n",
      "7352/7352 [==============================] - 43s 6ms/step - loss: 0.1229 - acc: 0.9531 - val_loss: 0.1902 - val_acc: 0.9186\n",
      "Epoch 139/300\n",
      "7352/7352 [==============================] - 43s 6ms/step - loss: 0.1146 - acc: 0.9544 - val_loss: 0.2064 - val_acc: 0.9270\n",
      "Epoch 140/300\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.1213 - acc: 0.9514 - val_loss: 0.1942 - val_acc: 0.9359\n",
      "Epoch 141/300\n",
      "7352/7352 [==============================] - 42s 6ms/step - loss: 0.1169 - acc: 0.9557 - val_loss: 0.3154 - val_acc: 0.9247\n",
      "Epoch 142/300\n",
      "7352/7352 [==============================] - 35s 5ms/step - loss: 0.1123 - acc: 0.9581 - val_loss: 0.2629 - val_acc: 0.9203\n",
      "Epoch 143/300\n",
      "7352/7352 [==============================] - 38s 5ms/step - loss: 0.1184 - acc: 0.9513 - val_loss: 0.2494 - val_acc: 0.9172\n",
      "Epoch 144/300\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1242 - acc: 0.9461 - val_loss: 0.2469 - val_acc: 0.9264\n",
      "Epoch 145/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1088 - acc: 0.9529 - val_loss: 0.2419 - val_acc: 0.9287\n",
      "Epoch 146/300\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1202 - acc: 0.9502 - val_loss: 0.1806 - val_acc: 0.9365\n",
      "Epoch 147/300\n",
      "7352/7352 [==============================] - 36s 5ms/step - loss: 0.1097 - acc: 0.9581 - val_loss: 0.2016 - val_acc: 0.9304\n",
      "Epoch 148/300\n",
      "7352/7352 [==============================] - 33s 4ms/step - loss: 0.1061 - acc: 0.9576 - val_loss: 0.2153 - val_acc: 0.9304\n",
      "Epoch 149/300\n",
      "7352/7352 [==============================] - 33s 4ms/step - loss: 0.1094 - acc: 0.9555 - val_loss: 0.2752 - val_acc: 0.9186\n",
      "Epoch 150/300\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1082 - acc: 0.9566 - val_loss: 0.1903 - val_acc: 0.9335\n",
      "Epoch 151/300\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1025 - acc: 0.9592 - val_loss: 0.2420 - val_acc: 0.9311\n",
      "Epoch 152/300\n",
      "7352/7352 [==============================] - 36s 5ms/step - loss: 0.1123 - acc: 0.9538 - val_loss: 0.5348 - val_acc: 0.9084\n",
      "Epoch 153/300\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.1685 - acc: 0.9403 - val_loss: 0.3885 - val_acc: 0.9074\n",
      "Epoch 154/300\n",
      "7352/7352 [==============================] - 42s 6ms/step - loss: 0.1104 - acc: 0.9525 - val_loss: 0.3885 - val_acc: 0.9121\n",
      "Epoch 155/300\n",
      "7352/7352 [==============================] - 38s 5ms/step - loss: 0.1115 - acc: 0.9553 - val_loss: 0.4237 - val_acc: 0.9067\n",
      "Epoch 156/300\n",
      "7352/7352 [==============================] - 33s 5ms/step - loss: 0.1192 - acc: 0.9527 - val_loss: 0.3781 - val_acc: 0.9121\n",
      "Epoch 157/300\n",
      "7352/7352 [==============================] - 33s 4ms/step - loss: 0.1104 - acc: 0.9597 - val_loss: 0.3931 - val_acc: 0.9101\n",
      "Epoch 158/300\n",
      "7352/7352 [==============================] - 40s 6ms/step - loss: 0.1098 - acc: 0.9574 - val_loss: 0.4060 - val_acc: 0.9036\n",
      "Epoch 159/300\n",
      "7352/7352 [==============================] - 35s 5ms/step - loss: 0.1059 - acc: 0.9597 - val_loss: 0.4586 - val_acc: 0.9111\n",
      "Epoch 160/300\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1320 - acc: 0.9453 - val_loss: 0.4208 - val_acc: 0.9046\n",
      "Epoch 161/300\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1115 - acc: 0.9499 - val_loss: 0.3814 - val_acc: 0.9179\n",
      "Epoch 162/300\n",
      "7352/7352 [==============================] - 35s 5ms/step - loss: 0.1088 - acc: 0.9548 - val_loss: 0.3911 - val_acc: 0.9131\n",
      "Epoch 163/300\n",
      "7352/7352 [==============================] - 33s 5ms/step - loss: 0.1092 - acc: 0.9536 - val_loss: 0.3895 - val_acc: 0.9091\n",
      "Epoch 164/300\n",
      "7352/7352 [==============================] - 42s 6ms/step - loss: 0.1108 - acc: 0.9533 - val_loss: 0.4051 - val_acc: 0.9118\n",
      "Epoch 165/300\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.1346 - acc: 0.9416 - val_loss: 0.3621 - val_acc: 0.9046\n",
      "Epoch 166/300\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.1300 - acc: 0.9486 - val_loss: 0.4221 - val_acc: 0.9030\n",
      "Epoch 167/300\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.1103 - acc: 0.9582 - val_loss: 0.3963 - val_acc: 0.9118\n",
      "Epoch 168/300\n",
      "7352/7352 [==============================] - 38s 5ms/step - loss: 0.1086 - acc: 0.9563 - val_loss: 0.4040 - val_acc: 0.9155\n",
      "Epoch 169/300\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.1089 - acc: 0.9576 - val_loss: 0.3659 - val_acc: 0.9213\n",
      "Epoch 170/300\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.1183 - acc: 0.9574 - val_loss: 0.3535 - val_acc: 0.9240\n",
      "Epoch 171/300\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.1005 - acc: 0.9574 - val_loss: 0.3521 - val_acc: 0.9253\n",
      "Epoch 172/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1005 - acc: 0.9578 - val_loss: 0.3467 - val_acc: 0.9213\n",
      "Epoch 173/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1092 - acc: 0.9588 - val_loss: 0.3244 - val_acc: 0.9237\n",
      "Epoch 174/300\n",
      "7352/7352 [==============================] - 38s 5ms/step - loss: 0.1034 - acc: 0.9597 - val_loss: 0.3471 - val_acc: 0.9189\n",
      "Epoch 175/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1028 - acc: 0.9561 - val_loss: 0.3762 - val_acc: 0.9240\n",
      "Epoch 176/300\n",
      "7352/7352 [==============================] - 38s 5ms/step - loss: 0.1072 - acc: 0.9561 - val_loss: 0.3787 - val_acc: 0.9152\n",
      "Epoch 177/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 38s 5ms/step - loss: 0.1093 - acc: 0.9557 - val_loss: 0.2953 - val_acc: 0.9199\n",
      "Epoch 178/300\n",
      "7352/7352 [==============================] - 38s 5ms/step - loss: 0.1101 - acc: 0.9555 - val_loss: 0.2767 - val_acc: 0.9257\n",
      "Epoch 179/300\n",
      "7352/7352 [==============================] - 38s 5ms/step - loss: 0.1004 - acc: 0.9573 - val_loss: 0.3647 - val_acc: 0.9135\n",
      "Epoch 180/300\n",
      "7352/7352 [==============================] - 38s 5ms/step - loss: 0.1120 - acc: 0.9547 - val_loss: 0.3763 - val_acc: 0.9128\n",
      "Epoch 181/300\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1104 - acc: 0.9510 - val_loss: 0.3103 - val_acc: 0.9220\n",
      "Epoch 182/300\n",
      "7352/7352 [==============================] - 33s 5ms/step - loss: 0.1223 - acc: 0.9531 - val_loss: 0.2781 - val_acc: 0.9220\n",
      "Epoch 183/300\n",
      "7352/7352 [==============================] - 33s 4ms/step - loss: 0.1390 - acc: 0.9354 - val_loss: 0.3215 - val_acc: 0.9040\n",
      "Epoch 184/300\n",
      "7352/7352 [==============================] - 33s 5ms/step - loss: 0.1504 - acc: 0.9373 - val_loss: 0.2201 - val_acc: 0.9152\n",
      "Epoch 185/300\n",
      "7352/7352 [==============================] - 33s 5ms/step - loss: 0.1139 - acc: 0.9502 - val_loss: 0.2741 - val_acc: 0.9179\n",
      "Epoch 186/300\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1104 - acc: 0.9514 - val_loss: 0.2795 - val_acc: 0.9223\n",
      "Epoch 187/300\n",
      "7352/7352 [==============================] - 33s 4ms/step - loss: 0.1100 - acc: 0.9524 - val_loss: 0.2881 - val_acc: 0.9213\n",
      "Epoch 188/300\n",
      "7352/7352 [==============================] - 33s 5ms/step - loss: 0.1043 - acc: 0.9528 - val_loss: 0.3015 - val_acc: 0.9243\n",
      "Epoch 189/300\n",
      "7352/7352 [==============================] - 37s 5ms/step - loss: 0.1056 - acc: 0.9540 - val_loss: 0.3048 - val_acc: 0.9230\n",
      "Epoch 190/300\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.1038 - acc: 0.9535 - val_loss: 0.3213 - val_acc: 0.9226\n",
      "Epoch 191/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1106 - acc: 0.9566 - val_loss: 0.2930 - val_acc: 0.9182\n",
      "Epoch 192/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.0998 - acc: 0.9584 - val_loss: 0.3319 - val_acc: 0.9203\n",
      "Epoch 193/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.0995 - acc: 0.9591 - val_loss: 0.3523 - val_acc: 0.9165\n",
      "Epoch 194/300\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.0993 - acc: 0.9600 - val_loss: 0.3443 - val_acc: 0.9165\n",
      "Epoch 195/300\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.0953 - acc: 0.9596 - val_loss: 0.3401 - val_acc: 0.9196\n",
      "Epoch 196/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1004 - acc: 0.9588 - val_loss: 0.3106 - val_acc: 0.9264\n",
      "Epoch 197/300\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.1170 - acc: 0.9572 - val_loss: 0.3888 - val_acc: 0.9114\n",
      "Epoch 198/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1590 - acc: 0.9431 - val_loss: 0.4784 - val_acc: 0.8836\n",
      "Epoch 199/300\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1601 - acc: 0.9457 - val_loss: 0.3825 - val_acc: 0.9104\n",
      "Epoch 200/300\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.1212 - acc: 0.9551 - val_loss: 0.3994 - val_acc: 0.8992\n",
      "Epoch 201/300\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.1406 - acc: 0.9517 - val_loss: 0.4694 - val_acc: 0.9009\n",
      "Epoch 202/300\n",
      "7352/7352 [==============================] - 42s 6ms/step - loss: 0.1190 - acc: 0.9570 - val_loss: 0.3219 - val_acc: 0.9125\n",
      "Epoch 203/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1104 - acc: 0.9582 - val_loss: 0.3370 - val_acc: 0.9091\n",
      "Epoch 204/300\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1087 - acc: 0.9580 - val_loss: 0.3402 - val_acc: 0.9087\n",
      "Epoch 205/300\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1143 - acc: 0.9529 - val_loss: 0.3496 - val_acc: 0.9091\n",
      "Epoch 206/300\n",
      "7352/7352 [==============================] - 37s 5ms/step - loss: 0.1066 - acc: 0.9578 - val_loss: 0.3605 - val_acc: 0.9128\n",
      "Epoch 207/300\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.1061 - acc: 0.9572 - val_loss: 0.4298 - val_acc: 0.9094\n",
      "Epoch 208/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1048 - acc: 0.9588 - val_loss: 0.4533 - val_acc: 0.9077\n",
      "Epoch 209/300\n",
      "7352/7352 [==============================] - 42s 6ms/step - loss: 0.1412 - acc: 0.9523 - val_loss: 0.3737 - val_acc: 0.8860\n",
      "Epoch 210/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1328 - acc: 0.9517 - val_loss: 0.3482 - val_acc: 0.9131\n",
      "Epoch 211/300\n",
      "7352/7352 [==============================] - 36s 5ms/step - loss: 0.1099 - acc: 0.9567 - val_loss: 0.3824 - val_acc: 0.9125\n",
      "Epoch 212/300\n",
      "7352/7352 [==============================] - 42s 6ms/step - loss: 0.1221 - acc: 0.9512 - val_loss: 0.3038 - val_acc: 0.9172\n",
      "Epoch 213/300\n",
      "7352/7352 [==============================] - 35s 5ms/step - loss: 0.1106 - acc: 0.9563 - val_loss: 0.3322 - val_acc: 0.9118\n",
      "Epoch 214/300\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.1044 - acc: 0.9558 - val_loss: 0.3228 - val_acc: 0.9114\n",
      "Epoch 215/300\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.1018 - acc: 0.9577 - val_loss: 0.3344 - val_acc: 0.9121\n",
      "Epoch 216/300\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.1019 - acc: 0.9566 - val_loss: 0.3498 - val_acc: 0.8901\n",
      "Epoch 217/300\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.1106 - acc: 0.9529 - val_loss: 0.3298 - val_acc: 0.9138\n",
      "Epoch 218/300\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.1015 - acc: 0.9589 - val_loss: 0.3060 - val_acc: 0.9162\n",
      "Epoch 219/300\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.1036 - acc: 0.9589 - val_loss: 0.2947 - val_acc: 0.9169\n",
      "Epoch 220/300\n",
      "7352/7352 [==============================] - 37s 5ms/step - loss: 0.0998 - acc: 0.9595 - val_loss: 0.2977 - val_acc: 0.9189\n",
      "Epoch 221/300\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.1021 - acc: 0.9577 - val_loss: 0.3121 - val_acc: 0.9138\n",
      "Epoch 222/300\n",
      "7352/7352 [==============================] - 38s 5ms/step - loss: 0.1232 - acc: 0.9478 - val_loss: 0.3291 - val_acc: 0.9074\n",
      "Epoch 223/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1313 - acc: 0.9422 - val_loss: 0.3256 - val_acc: 0.9084\n",
      "Epoch 224/300\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.1422 - acc: 0.9404 - val_loss: 0.3754 - val_acc: 0.8836\n",
      "Epoch 225/300\n",
      "7352/7352 [==============================] - 40s 6ms/step - loss: 0.1183 - acc: 0.9465 - val_loss: 0.2778 - val_acc: 0.9131\n",
      "Epoch 226/300\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.1113 - acc: 0.9495 - val_loss: 0.2932 - val_acc: 0.9091\n",
      "Epoch 227/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1080 - acc: 0.9542 - val_loss: 0.2910 - val_acc: 0.9175\n",
      "Epoch 228/300\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.1227 - acc: 0.9482 - val_loss: 0.2493 - val_acc: 0.9036\n",
      "Epoch 229/300\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.1321 - acc: 0.9415 - val_loss: 0.2344 - val_acc: 0.9165\n",
      "Epoch 230/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1082 - acc: 0.9520 - val_loss: 0.2478 - val_acc: 0.9209\n",
      "Epoch 231/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1069 - acc: 0.9565 - val_loss: 0.2543 - val_acc: 0.9206\n",
      "Epoch 232/300\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.1031 - acc: 0.9573 - val_loss: 0.2796 - val_acc: 0.9179\n",
      "Epoch 233/300\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.1065 - acc: 0.9540 - val_loss: 0.2629 - val_acc: 0.9148\n",
      "Epoch 234/300\n",
      "7352/7352 [==============================] - 40s 6ms/step - loss: 0.1051 - acc: 0.9558 - val_loss: 0.2588 - val_acc: 0.9196\n",
      "Epoch 235/300\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.1076 - acc: 0.9543 - val_loss: 0.2726 - val_acc: 0.9196\n",
      "Epoch 236/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1107 - acc: 0.9567 - val_loss: 0.2582 - val_acc: 0.9209\n",
      "Epoch 237/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1041 - acc: 0.9589 - val_loss: 0.2747 - val_acc: 0.9213\n",
      "Epoch 238/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1127 - acc: 0.9548 - val_loss: 0.3241 - val_acc: 0.9260\n",
      "Epoch 239/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1108 - acc: 0.9577 - val_loss: 0.3341 - val_acc: 0.9141\n",
      "Epoch 240/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1044 - acc: 0.9584 - val_loss: 0.3490 - val_acc: 0.9216\n",
      "Epoch 241/300\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.1019 - acc: 0.9593 - val_loss: 0.3596 - val_acc: 0.9179\n",
      "Epoch 242/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.0995 - acc: 0.9580 - val_loss: 0.3850 - val_acc: 0.9158\n",
      "Epoch 243/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1423 - acc: 0.9482 - val_loss: 0.2963 - val_acc: 0.9118\n",
      "Epoch 244/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1149 - acc: 0.9525 - val_loss: 0.2650 - val_acc: 0.9169\n",
      "Epoch 245/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1112 - acc: 0.9521 - val_loss: 0.2914 - val_acc: 0.9186\n",
      "Epoch 246/300\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.1070 - acc: 0.9562 - val_loss: 0.3066 - val_acc: 0.9158\n",
      "Epoch 247/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1038 - acc: 0.9554 - val_loss: 0.2874 - val_acc: 0.9138\n",
      "Epoch 248/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1011 - acc: 0.9569 - val_loss: 0.2966 - val_acc: 0.9226\n",
      "Epoch 249/300\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.0997 - acc: 0.9592 - val_loss: 0.3340 - val_acc: 0.9155\n",
      "Epoch 250/300\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.0953 - acc: 0.9595 - val_loss: 0.3080 - val_acc: 0.9243\n",
      "Epoch 251/300\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.0965 - acc: 0.9599 - val_loss: 0.3177 - val_acc: 0.9158\n",
      "Epoch 252/300\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.1134 - acc: 0.9539 - val_loss: 0.3525 - val_acc: 0.9108\n",
      "Epoch 253/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1013 - acc: 0.9581 - val_loss: 0.3174 - val_acc: 0.9128\n",
      "Epoch 254/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.0947 - acc: 0.9606 - val_loss: 0.3213 - val_acc: 0.9121\n",
      "Epoch 255/300\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.0995 - acc: 0.9589 - val_loss: 0.2974 - val_acc: 0.9101\n",
      "Epoch 256/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.0969 - acc: 0.9591 - val_loss: 0.3113 - val_acc: 0.9162\n",
      "Epoch 257/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.0946 - acc: 0.9585 - val_loss: 0.3303 - val_acc: 0.9196\n",
      "Epoch 258/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1006 - acc: 0.9569 - val_loss: 0.3293 - val_acc: 0.9104\n",
      "Epoch 259/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1617 - acc: 0.9434 - val_loss: 0.3092 - val_acc: 0.9182\n",
      "Epoch 260/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1136 - acc: 0.9527 - val_loss: 0.3562 - val_acc: 0.9101\n",
      "Epoch 261/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1338 - acc: 0.9509 - val_loss: 0.2752 - val_acc: 0.9152\n",
      "Epoch 262/300\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.1070 - acc: 0.9569 - val_loss: 0.2944 - val_acc: 0.9131\n",
      "Epoch 263/300\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.1031 - acc: 0.9559 - val_loss: 0.2828 - val_acc: 0.9209\n",
      "Epoch 264/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.0982 - acc: 0.9573 - val_loss: 0.2942 - val_acc: 0.9155\n",
      "Epoch 265/300\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.0991 - acc: 0.9578 - val_loss: 0.3022 - val_acc: 0.9206\n",
      "Epoch 266/300\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1367 - acc: 0.9411 - val_loss: 0.3443 - val_acc: 0.9063\n",
      "Epoch 267/300\n",
      "7352/7352 [==============================] - 40s 6ms/step - loss: 0.1390 - acc: 0.9418 - val_loss: 0.3310 - val_acc: 0.9121\n",
      "Epoch 268/300\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1270 - acc: 0.9441 - val_loss: 0.3294 - val_acc: 0.9118\n",
      "Epoch 269/300\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1168 - acc: 0.9453 - val_loss: 0.3340 - val_acc: 0.9125\n",
      "Epoch 270/300\n",
      "7352/7352 [==============================] - 33s 4ms/step - loss: 0.1128 - acc: 0.9487 - val_loss: 0.3162 - val_acc: 0.9148\n",
      "Epoch 271/300\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1107 - acc: 0.9527 - val_loss: 0.3478 - val_acc: 0.9158\n",
      "Epoch 272/300\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1079 - acc: 0.9512 - val_loss: 0.3339 - val_acc: 0.9196\n",
      "Epoch 273/300\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1077 - acc: 0.9517 - val_loss: 0.3560 - val_acc: 0.9091\n",
      "Epoch 274/300\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1112 - acc: 0.9548 - val_loss: 0.3969 - val_acc: 0.9189\n",
      "Epoch 275/300\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.1090 - acc: 0.9529 - val_loss: 0.4262 - val_acc: 0.9152\n",
      "Epoch 276/300\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.1058 - acc: 0.9544 - val_loss: 0.4264 - val_acc: 0.9152\n",
      "Epoch 277/300\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1123 - acc: 0.9528 - val_loss: 0.3424 - val_acc: 0.9118\n",
      "Epoch 278/300\n",
      "7352/7352 [==============================] - 33s 5ms/step - loss: 0.1090 - acc: 0.9550 - val_loss: 0.4050 - val_acc: 0.9182\n",
      "Epoch 279/300\n",
      "7352/7352 [==============================] - 36s 5ms/step - loss: 0.1832 - acc: 0.9363 - val_loss: 0.3758 - val_acc: 0.9131\n",
      "Epoch 280/300\n",
      "7352/7352 [==============================] - 37s 5ms/step - loss: 0.1165 - acc: 0.9506 - val_loss: 0.3636 - val_acc: 0.9175\n",
      "Epoch 281/300\n",
      "7352/7352 [==============================] - 35s 5ms/step - loss: 0.1097 - acc: 0.9525 - val_loss: 0.3354 - val_acc: 0.9209\n",
      "Epoch 282/300\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1055 - acc: 0.9539 - val_loss: 0.3695 - val_acc: 0.9155\n",
      "Epoch 283/300\n",
      "7352/7352 [==============================] - 36s 5ms/step - loss: 0.1048 - acc: 0.9558 - val_loss: 0.3416 - val_acc: 0.9182\n",
      "Epoch 284/300\n",
      "7352/7352 [==============================] - 36s 5ms/step - loss: 0.1137 - acc: 0.9538 - val_loss: 0.3538 - val_acc: 0.9226\n",
      "Epoch 285/300\n",
      "7352/7352 [==============================] - 36s 5ms/step - loss: 0.1051 - acc: 0.9569 - val_loss: 0.3387 - val_acc: 0.9233\n",
      "Epoch 286/300\n",
      "7352/7352 [==============================] - 35s 5ms/step - loss: 0.1029 - acc: 0.9585 - val_loss: 0.3602 - val_acc: 0.9243\n",
      "Epoch 287/300\n",
      "7352/7352 [==============================] - 35s 5ms/step - loss: 0.0993 - acc: 0.9584 - val_loss: 0.3452 - val_acc: 0.9260\n",
      "Epoch 288/300\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.0944 - acc: 0.9603 - val_loss: 0.3491 - val_acc: 0.9247\n",
      "Epoch 289/300\n",
      "7352/7352 [==============================] - 42s 6ms/step - loss: 0.0933 - acc: 0.9581 - val_loss: 0.3627 - val_acc: 0.9298\n",
      "Epoch 290/300\n",
      "7352/7352 [==============================] - 36s 5ms/step - loss: 0.0993 - acc: 0.9574 - val_loss: 0.3549 - val_acc: 0.9253\n",
      "Epoch 291/300\n",
      "7352/7352 [==============================] - 35s 5ms/step - loss: 0.0943 - acc: 0.9585 - val_loss: 0.3652 - val_acc: 0.9264\n",
      "Epoch 292/300\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.0960 - acc: 0.9593 - val_loss: 0.3524 - val_acc: 0.9304\n",
      "Epoch 293/300\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.0958 - acc: 0.9597 - val_loss: 0.3371 - val_acc: 0.9308\n",
      "Epoch 294/300\n",
      "7352/7352 [==============================] - 33s 5ms/step - loss: 0.0945 - acc: 0.9576 - val_loss: 0.3549 - val_acc: 0.9233\n",
      "Epoch 295/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1000 - acc: 0.9573 - val_loss: 0.3639 - val_acc: 0.9352\n",
      "Epoch 296/300\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1204 - acc: 0.9567 - val_loss: 0.2257 - val_acc: 0.9413\n",
      "Epoch 297/300\n",
      "7352/7352 [==============================] - 33s 4ms/step - loss: 0.0881 - acc: 0.9604 - val_loss: 0.2184 - val_acc: 0.9389\n",
      "Epoch 298/300\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.0848 - acc: 0.9618 - val_loss: 0.2433 - val_acc: 0.9393\n",
      "Epoch 299/300\n",
      "7352/7352 [==============================] - 33s 5ms/step - loss: 0.0939 - acc: 0.9603 - val_loss: 0.1992 - val_acc: 0.9355\n",
      "Epoch 300/300\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.0990 - acc: 0.9582 - val_loss: 0.2177 - val_acc: 0.9325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f1cd453860>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  0      378       113        0                   0   \n",
      "STANDING                 0       59       473        0                   0   \n",
      "WALKING                  0        0         0      496                   0   \n",
      "WALKING_DOWNSTAIRS       0        1         0       12                 399   \n",
      "WALKING_UPSTAIRS         0        2         1        3                   0   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            0  \n",
      "STANDING                           0  \n",
      "WALKING                            0  \n",
      "WALKING_DOWNSTAIRS                 8  \n",
      "WALKING_UPSTAIRS                 465  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 3s 897us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.21770981482614904, 0.9324737020699015]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With a simple 2 layer architecture we got 93.24% accuracy and a loss of 0.21\n",
    "- We can further imporve the performace with Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Here we seen thatby using two layered LSTM, we got a accuracy of 93.24% with loss of 0.21% .DeeP Learning help us to built models even when we don't have domain expert engineered features.\n",
    "2.LSTM model can  give good result by doing more hypertuning.\n",
    "3.In this case study for better accuracy I had checked different epochs with different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
